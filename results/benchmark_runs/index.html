<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HDH-Bench: Healthcare Data Harmonization Benchmark Results</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Times New Roman', Times, serif;
            line-height: 1.6;
            color: #000;
            background: #fff;
            padding: 40px;
            max-width: 1000px;
            margin: 0 auto;
        }

        header {
            border-bottom: 2px solid #000;
            padding-bottom: 20px;
            margin-bottom: 40px;
        }

        h1 {
            font-size: 24pt;
            font-weight: bold;
            margin-bottom: 10px;
            text-align: center;
        }

        .subtitle {
            text-align: center;
            font-size: 12pt;
            font-style: italic;
            margin-bottom: 20px;
        }

        .metadata {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin-bottom: 30px;
            padding: 15px;
            border: 1px solid #ccc;
            background: #f9f9f9;
        }

        .metadata-item {
            text-align: center;
        }

        .metadata-item label {
            display: block;
            font-weight: bold;
            font-size: 9pt;
            text-transform: uppercase;
            margin-bottom: 5px;
        }

        .metadata-item .value {
            font-size: 11pt;
        }

        h2 {
            font-size: 16pt;
            font-weight: bold;
            margin-top: 40px;
            margin-bottom: 20px;
            border-bottom: 1px solid #000;
            padding-bottom: 5px;
        }

        h3 {
            font-size: 12pt;
            font-weight: bold;
            margin-top: 25px;
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 10px;
            text-align: justify;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 10pt;
        }

        th, td {
            border: 1px solid #000;
            padding: 8px;
            text-align: left;
        }

        th {
            background: #f0f0f0;
            font-weight: bold;
            text-align: center;
        }

        td {
            text-align: center;
        }

        td.text-left {
            text-align: left;
        }

        .abstract {
            margin: 30px 0;
            padding: 20px;
            border: 1px solid #000;
            background: #f9f9f9;
        }

        .abstract h3 {
            margin-top: 0;
        }

        ul {
            margin: 10px 0 10px 30px;
        }

        li {
            margin-bottom: 5px;
        }

        .footnote {
            font-size: 9pt;
            margin-top: 30px;
            padding-top: 10px;
            border-top: 1px solid #ccc;
        }

        code {
            font-family: 'Courier New', Courier, monospace;
            background: #f5f5f5;
            padding: 2px 4px;
            font-size: 9pt;
        }

        pre {
            background: #f5f5f5;
            padding: 10px;
            border: 1px solid #ddd;
            overflow-x: auto;
            margin: 10px 0;
            font-size: 9pt;
        }
    </style>
</head>
<body>
    <header>
        <h1>HDH-Bench: Healthcare Data Harmonization Benchmark</h1>
        <div class="subtitle">Evaluating AI Agents on Multi-System FHIR Data Integration Tasks</div>
    </header>

    <div class="metadata">
        <div class="metadata-item">
            <label>Benchmark Version</label>
            <div class="value">1.0.0</div>
        </div>
        <div class="metadata-item">
            <label>Test Date</label>
            <div class="value">2026-02-04</div>
        </div>
        <div class="metadata-item">
            <label>Systems Tested</label>
            <div class="value">6 FHIR R4 APIs</div>
        </div>
    </div>

    <div class="abstract">
        <h3>Abstract</h3>
        <p>This report presents the results of HDH-Bench, a benchmark designed to evaluate AI agents on healthcare data integration tasks. The benchmark tests agent capabilities across six distinct clinical scenarios requiring discovery, querying, and harmonization of data from multiple FHIR R4-compliant healthcare systems (EHR, LIS, RIS, Pharmacy, PAS, Billing). Results are validated against ground truth data derived from a master patient index.</p>
    </div>

    <h2>1. Executive Summary</h2>

    <p>Three independent test runs were conducted using Claude Sonnet 4.5 (Anthropic) across all six benchmark tasks. The agent demonstrated consistent performance with an average accuracy of 44.3% (σ = 4.8%) across runs.</p>

    <table>
        <thead>
            <tr>
                <th>Agent</th>
                <th>Run 1</th>
                <th>Run 2</th>
                <th>Run 3</th>
                <th>Mean</th>
                <th>Std Dev</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="text-left">Claude Sonnet 4.5</td>
                <td>38.3%</td>
                <td>47.5%</td>
                <td>47.1%</td>
                <td>44.3%</td>
                <td>4.8%</td>
            </tr>
        </tbody>
    </table>

    <h2>2. Methodology</h2>

    <h3>2.1 Benchmark Design</h3>
    <p>HDH-Bench consists of six tasks designed to evaluate different aspects of healthcare data integration:</p>
    <ul>
        <li><strong>Q001 - Patient 360 View:</strong> Cross-system patient record matching across 6 healthcare systems</li>
        <li><strong>Q002 - Diabetic Cohort Building:</strong> Multi-system cohort identification using diagnosis and medication data</li>
        <li><strong>Q003 - Abnormal Laboratory Results:</strong> Clinical data filtering for patients with HbA1c &gt; 9.0%</li>
        <li><strong>Q004 - Duplicate Patient Detection:</strong> Identification of duplicate patient records using demographic matching</li>
        <li><strong>Q005 - Cross-System Cohort Validation:</strong> Complex multi-constraint query with cross-system validation</li>
        <li><strong>Q006 - Data Quality Assessment:</strong> Detection of orphaned results and abandoned orders</li>
    </ul>

    <h3>2.2 Systems Under Test</h3>
    <p>The benchmark environment consists of six independent FHIR R4-compliant API endpoints representing typical healthcare system architecture:</p>
    <ul>
        <li>Electronic Health Record (EHR) system</li>
        <li>Laboratory Information System (LIS)</li>
        <li>Radiology Information System (RIS)</li>
        <li>Pharmacy Management System</li>
        <li>Patient Administration System (PAS)</li>
        <li>Billing System</li>
    </ul>

    <h3>2.3 Validation Methodology</h3>
    <p>All agent responses are validated against ground truth data maintained in a master patient index. Scoring is performed automatically using task-specific validation criteria. Pass/fail thresholds vary by task complexity and clinical requirements.</p>

    <h2>3. Results</h2>

    <h3>3.1 Overall Performance</h3>

    <table>
        <thead>
            <tr>
                <th>Run ID</th>
                <th>Overall Score</th>
                <th>Execution Time</th>
                <th>API Calls</th>
                <th>Tasks Passed</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>20260204_172804</td>
                <td>38.3%</td>
                <td>200s</td>
                <td>41</td>
                <td>2/6</td>
            </tr>
            <tr>
                <td>20260204_173323</td>
                <td>47.5%</td>
                <td>302s</td>
                <td>68</td>
                <td>2/6</td>
            </tr>
            <tr>
                <td>20260204_183944</td>
                <td>47.1%</td>
                <td>329s</td>
                <td>75</td>
                <td>2/6</td>
            </tr>
        </tbody>
    </table>

    <h3>3.2 Task-Level Performance</h3>

    <table>
        <thead>
            <tr>
                <th rowspan="2">Task</th>
                <th colspan="3">Score by Run (%)</th>
                <th rowspan="2">Mean</th>
                <th rowspan="2">Pass Rate</th>
            </tr>
            <tr>
                <th>Run 1</th>
                <th>Run 2</th>
                <th>Run 3</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="text-left">Q001: Patient 360 View</td>
                <td>100.0</td>
                <td>100.0</td>
                <td>83.3</td>
                <td>94.4</td>
                <td>3/3</td>
            </tr>
            <tr>
                <td class="text-left">Q002: Diabetic Cohort</td>
                <td>100.0</td>
                <td>100.0</td>
                <td>100.0</td>
                <td>100.0</td>
                <td>3/3</td>
            </tr>
            <tr>
                <td class="text-left">Q003: Abnormal Glucose</td>
                <td>30.0</td>
                <td>40.7</td>
                <td>56.3</td>
                <td>42.3</td>
                <td>0/3</td>
            </tr>
            <tr>
                <td class="text-left">Q004: Duplicate Detection</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0/3</td>
            </tr>
            <tr>
                <td class="text-left">Q005: Cross-System Cohort</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0.0</td>
                <td>0/3</td>
            </tr>
            <tr>
                <td class="text-left">Q006: Data Quality Issues</td>
                <td>0.0</td>
                <td>44.0</td>
                <td>42.8</td>
                <td>29.0</td>
                <td>0/3</td>
            </tr>
        </tbody>
    </table>

    <h3>3.3 Detailed Task Analysis</h3>

    <h4>Q001: Patient 360 View (Cross-System Matching)</h4>
    <p><strong>Objective:</strong> Identify all records for patient "Sarah Johnson" (DOB: 1978-03-15) across six healthcare systems.</p>
    <p><strong>Performance:</strong> Mean accuracy 94.4% (100%, 100%, 83.3%). The agent successfully matched patient records across 5-6 systems in all runs. Run 3 failed to identify the RIS system record (RAD-300042).</p>

    <h4>Q002: Diabetic Cohort Building</h4>
    <p><strong>Objective:</strong> Identify all patients with Type 2 diabetes on metformin therapy.</p>
    <p><strong>Performance:</strong> Mean accuracy 100% (100%, 100%, 100%). Perfect consistency across all three runs. The agent correctly identified 134 patients matching the criteria (ground truth range: 92-154).</p>

    <h4>Q003: Abnormal Laboratory Results</h4>
    <p><strong>Objective:</strong> Identify patients with HbA1c test results greater than 9.0%.</p>
    <p><strong>Performance:</strong> Mean accuracy 42.3% (30.0%, 40.7%, 56.3%). Progressive improvement observed across runs. Final run identified 40 patients (ground truth: 71), representing 56.3% recall.</p>

    <h4>Q004: Duplicate Patient Detection</h4>
    <p><strong>Objective:</strong> Identify duplicate patient records using demographic matching algorithms.</p>
    <p><strong>Performance:</strong> Mean accuracy 0% (0%, 0%, 0%). The agent failed to identify duplicate groups in all runs. Identified 7 groups versus expected range of 39-59 groups.</p>

    <h4>Q005: Cross-System Cohort with Validation</h4>
    <p><strong>Objective:</strong> Identify diabetic patients with recent HbA1c tests, validated across all systems.</p>
    <p><strong>Performance:</strong> Mean accuracy 0% (0%, 0%, 0%). The agent failed to produce valid cross-system validated matches in all runs.</p>

    <h4>Q006: Data Quality Assessment</h4>
    <p><strong>Objective:</strong> Identify orphaned laboratory results and abandoned medication orders.</p>
    <p><strong>Performance:</strong> Mean accuracy 29.0% (0%, 44.0%, 42.8%). Improved performance in Runs 2-3. Run 3 identified 101 orphaned results (expected: 113-123) and 40 abandoned orders (expected: 15-25).</p>

    <h2>4. Discussion</h2>

    <h3>4.1 Key Findings</h3>
    <ul>
        <li><strong>Consistent Performance:</strong> The agent demonstrated stable performance across multiple runs with standard deviation of 4.8%.</li>
        <li><strong>Strong Basic Operations:</strong> Q001 and Q002 show that the agent can reliably perform patient matching and simple cohort identification.</li>
        <li><strong>Learning Curve:</strong> Q003 performance improved from 30% to 56% across runs, suggesting potential for optimization.</li>
        <li><strong>Complex Task Limitations:</strong> Q004 and Q005 failures indicate difficulty with advanced deduplication algorithms and multi-constraint validation.</li>
    </ul>

    <h3>4.2 Performance Characteristics</h3>
    <p>Execution time increased with task complexity, ranging from 200-329 seconds per complete benchmark run. API call volume varied from 41-75 calls, with higher call counts correlating with improved task performance, particularly on Q003 and Q006.</p>

    <h3>4.3 Limitations</h3>
    <ul>
        <li>Single agent architecture tested; multi-agent comparisons not performed</li>
        <li>Limited to FHIR R4 API interactions; other healthcare data formats not evaluated</li>
        <li>Synthetic test data; real-world data variability not captured</li>
        <li>Three runs provide limited statistical power for variance analysis</li>
    </ul>

    <h2>5. Conclusion</h2>

    <p>Claude Sonnet 4.5 demonstrates capability for basic healthcare data integration tasks, achieving 100% accuracy on standard cohort identification and near-perfect patient matching. Performance on complex tasks requiring advanced deduplication and cross-system validation remains limited. The agent's consistent performance across runs (44.3% ± 4.8%) and improvement trajectory on certain tasks suggests potential for optimization through prompt engineering or architectural enhancements.</p>

    <h2>6. Technical Specifications</h2>

    <table>
        <thead>
            <tr>
                <th>Parameter</th>
                <th>Value</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="text-left">Agent Model</td>
                <td class="text-left">Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)</td>
            </tr>
            <tr>
                <td class="text-left">API Protocol</td>
                <td class="text-left">Anthropic Direct API with tool use</td>
            </tr>
            <tr>
                <td class="text-left">FHIR Version</td>
                <td class="text-left">R4 (4.0.1)</td>
            </tr>
            <tr>
                <td class="text-left">Validation Method</td>
                <td class="text-left">Ground truth comparison against master patient index</td>
            </tr>
            <tr>
                <td class="text-left">Test Environment</td>
                <td class="text-left">Local FHIR servers (6 independent systems)</td>
            </tr>
            <tr>
                <td class="text-left">Total Test Runs</td>
                <td class="text-left">3</td>
            </tr>
        </tbody>
    </table>

    <h2>7. Reproducibility</h2>

    <p>All benchmark runs are stored in versioned directories with complete validation data:</p>
    <pre>
results/benchmark_runs/
├── 20260204_172804/  (Run 1: 38.3%)
├── 20260204_173323/  (Run 2: 47.5%)
└── 20260204_183944/  (Run 3: 47.1%)
    ├── metadata.json      (execution parameters)
    ├── raw_results.json   (agent responses)
    ├── validation.json    (ground truth comparison)
    └── REPORT.md          (human-readable summary)
    </pre>

    <p>Benchmark execution command:</p>
    <pre>python3 scripts/run_validated_benchmark.py --agents claude --all-tasks</pre>

    <div class="footnote">
        <p><strong>Generated:</strong> 2026-02-04 | <strong>Repository:</strong> healthcare-data-poc | <strong>Benchmark Version:</strong> HDH-Bench v1.0.0</p>
    </div>
</body>
</html>
